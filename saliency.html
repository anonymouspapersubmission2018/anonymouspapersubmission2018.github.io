<h1>Saliency Maps </h1>
<h2>Learning Audio and Visual Representations for Multimodal Music Genre Classification</h2>
<p>We use <a href="https://github.com/zhanghang1989/visualResNet_torch">this implementation</a> of the paper <a href="https://arxiv.org/abs/1512.04150">Learning Deep Features for Discriminative Localization</a></p>
<p>Each page includes the test set images of each category. Opening each of the links below, you can find the predictions of the visual model. The predited class (and its probability) is printed with a small red font on the top-left of each image. </p>

<p><a href="Blues.html">Blues</a></p>

<p><a href="Country.html">Country</a></p>

<p><a href="Electronic.html">Electronic</a></p>

<p><a href="Folk.html">Folk</a></p>

<p><a href="Jazz.html">Jazz</a></p>

<p><a href="Latin.html">Latin</a></p>

<p><a href="Metal.html">Metal</a></p>

<p><a href="Newage.html">Newage</a></p>

<p><a href="Pop.html">Pop</a></p>

<p><a href="Punk.html">Punk</a></p>

<p><a href="Rap.html">Rap</a></p>

<p><a href="Reggae.html">Reggae</a></p>

<p><a href="RnB.html">RnB</a></p>

<p><a href="Rock.html">Rock</a></p>

<p><a href="World.html">World</a></p>

